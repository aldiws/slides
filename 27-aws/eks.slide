AWS Pop-up Loft: Deploying Go Apps on the Cloud

Kenneth Shaw
ken@brank.as

23 October 2019

Tags: golang, kubernetes, amazon web services, aws, postgres

* GoJakarta

.background gopher-720p.png

* First...

Big thank you to [[https://aws.amazon.com/][Amazon Web Services]] for hosting this event!

Please join the us online if you're not yet a member!

- Meetup: [[https://www.meetup.com/GoJakarta][meetup.com/GoJakarta]] 
- Telegram: [[https://t.me/gophers_id][t.me/gophers_id]]
- Facebook: [[https://www.facebook.com/groups/GophersID][facebook.com/groups/GophersID]]

* About GoJakarta

GoJakarta is a monthly meetup focused on the Go programming language, but also incorporates other topics related to Go such as deploying Go apps to the cloud.

Slides available at [[https://gophers.id/slides][gophers.id/slides]]:

    $ go get -u gophers.id/slides

* Presenters + Contact

Looking for presenters! We need presenters! If you would like to do a presentation, have a suggestion for a topic, or have a location we can use!

Contact us: 

Ken Shaw

- [[mailto:kenshaw@gmail.com][kenshaw@gmail.com]]
- [[tel:+62-811-168-1586][+62-811-168-1586]]

Vidya Winda Sari

- [[mailto:vidya.winda@gmail.com][vidya.winda@gmail.com]]
- [[tel:+62-812-8640-1328][+62-812-8640-1328]]

* Next Meetup

November 10th, 2019, topic/location: TBA

* Deploying Go Apps on the Cloud

.background gopher-720p.png

* Anatomy of a Go Web App

* Brankas is Hiring!

Brankas is hiring for all positions:

- Country Manager (Indonesia)
- Sales and Marketing
- Solution Architects
- Engineering Managers
- Backend/Frontend Engineers
- Platform and Site Reliability Engineers
- Business Analysts
- QA

Please email a CV / cover letter to: [[mailto:careers@brank.as][careers@brank.as]]

.background brankas-hiring.png

* Mission Overview

Build a standard REST app to read/write from a database, and scale it to infinity with Amazon Web Services.

* App Overview

Showcase simple `authors` and `books` example:

- `authors` have a `name`, and can be found by `name`
- `books` have an `author`, and have a number of other fields (`date`, `isbn`, ...)

Use (mostly) the Go standard library to showcase how easy this can be:

- Overview organization and package layout
- Use `github.com/brankas/goji` for simple for URL route handling
- PostgreSQL database

* File and Package Layout

  $ ls $GOPATH/src/gophers.id/slides/27-aws/webapp
  main.go  models   services

Very simple package layout:

    models    - database models and schema
    services  - API service handler

* Setup Local Database

Create a simple Docker `testnet` network:

    $ docker network create testnet

Spin up a local PostgreSQL database for testing:

    $ docker run \
        --name postgres \
        --env POSTGRES_PASSWORD=P4ssw0rd \
        --rm \
        --detach \
        --network testnet \
        --publish 5432:5432 \
        postgres 

* PostgreSQL Schema

.code webapp/models/schema.sql /DROP/,/--/

* PostgreSQL Schema (cont'd)

.code webapp/models/schema.sql /TABLE books/,/title_year/

* Generating Models from Schema

.code webapp/models/gen.sh

* Go Server Implementation

.code webapp/main.go /package/,/^\)/

* Go Server Implementation (cont'd)

.code webapp/main.go /var/,/^}/

* Go Server Implementation (cont'd)

.code webapp/main.go /func run/,/^}/

* Go Server Implementation (cont'd)

- Models
- Services

* Building the Web App

.code build.sh

* Dockerfile

.code Dockerfile

* Building and Testing with Docker

First, build a `sample-api` image:

    $ docker build -t sample-api .

Then, run the image locally for testing:

    $ docker run \
        --name sample-api \
        --rm \
        --network testnet \
        --publish 8080:8080 \
        sample-api

* Deploying on Amazon Web Services

* Brankas is Hiring!

Brankas is hiring for all positions:

- Country Manager (Indonesia)
- Sales and Marketing
- Solution Architects
- Engineering Managers
- Backend/Frontend Engineers
- Platform and Site Reliability Engineers
- Business Analysts
- QA

Please email a CV / cover letter to: [[mailto:careers@brank.as][careers@brank.as]]

.background brankas-hiring.png

* Scalable Overview

Our goal for tonight is to be able to scale our web app "to infinity." 

We will accomplish that by leveraging Amazon Web Services' (AWS) Elastic Kubernetes Service (EKS) and Relational Database Service (RDS). EKS and RDS will allow us to dynamically scale our computing environment/database to any size, speed, or throughput we need. 

With EKS it's simple to scale up to hundreds (or thousands!) of web app frontends speaking to a fully managed, backend PostgreSQL RDS database spanning hundreds (or thousands!) of instances.

* Setup Tools

We'll use the `aws`, `eksctl`, and `kubectl` command-line interfaces to create and setup our EKS and RDS instances, and to later deploy, configure, and scale our web app.

Install the `aws` command-line tool:

macOS + Linux:

    $ pip3 install awscli --upgrade --user

Windows:

- [[https://docs.aws.amazon.com/cli/latest/userguide/install-windows.html#install-msi-on-windows][Download `.msi` file from AWS and install]]

Then, configure and check that `aws` is working:

    $ aws configure
    $ aws ec2 describe-regions 

* Setup Tools (cont'd)

Unfortunately the `eksctl` and `kubectl` installs are different for macOS, Linux, and Windows:

- [[https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html][Follow instructions for setting up `eksctl` for your OS]]
- [[https://kubernetes.io/docs/tasks/tools/install-kubectl/][Follow instructions for setting up `kubectl` for your OS]]

Check `eksctl` is version `0.7.0` or higher:

    $ eksctl version
    [â„¹]  version.Info{BuiltAt:"", GitCommit:"", GitTag:"0.7.0"}

Check `kubectl` is version `v1.14.0` or higher:

	$ kubectl version
	Client Version: version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.2", GitCommit:"c97fe5036ef3df2967d086711e6c0c405941e14b", GitTreeState:"clean", BuildDate:"2019-10-15T19:18:23Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"linux/amd64"}
	Server Version: version.Info{Major:"1", Minor:"14+", GitVersion:"v1.14.6-eks-5047ed", GitCommit:"5047edce664593832e9b889e447ac75ab104f527", GitTreeState:"clean", BuildDate:"2019-08-21T22:32:40Z", GoVersion:"go1.12.9", Compiler:"gc", Platform:"linux/amd64"}

* Notes on Joining EKS and RDS Networks

Enabling EKS to speak to RDS requires a bit of work, but is fairly simple. Essentially, we create a private network that routes traffic between the EKS and RDS networks. 

On AWS, this is accomplished by using the Virtual Private Cloud (VPC) service. When an EKS cluster is created, it is given its own private network that can be peered with any VPC instance. And, when an RDS instance is created, you can also assign it a VPC network that you have created. 

As such, we will create a VPC and assign it to RDS when we create the RDS instance, carefully choosing a network space that will not clash with the EKS network space. We will then peer the RDS and EKS networks using the created VPC.

We will configure RDS instances to use the `10.0.0.0/24` network, and we'll leave EKS to use the default `192.168.0.0/24` network.

* Create VPC for RDS to Peer with EKS

Create a private VPC, that will be assigned to a RDS instance we will create later: 

    $ aws ec2 create-vpc \
        --cidr-block 10.0.0.0/24

The above will show a `VpcId`, save it for use later:

    $ export RDSVPCID="vpc-05be9f2c8868bcd51"

* Create VPC Subnets

RDS requires a subnet for each availability zone RDS instances will be created in. Create two subnets on the VPC, one for each availability zone we will use:

    $ aws ec2 create-subnet \
        --vpc-id "$RDSVPCID" \
        --availability-zone ap-southeast-1a \
        --cidr-block 10.0.0.0/25
    $ aws ec2 create-subnet \
        --vpc-id "$RDSVPCID" \
        --availability-zone ap-southeast-1b \
        --cidr-block 10.0.0.128/25

Each of the above will show a `SubnetId`, save them for use later:

    $ export RDSSUBNETID1="subnet-0cc1c35847d811c3a"
    $ export RDSSUBNETID2="subnet-0759e1197b51559b1"

*Note*: We're splitting each AZ's subnet into `/25` so that a `/24` can be easily routed from EKS to RDS. When using more availability zones for RDS, choose a network route and mask that makes the most sense for your configuration.

* Associate Subnets with VPC

The route table for the VPC needs to be associated with the created subnets.

First, grab the route table for the created VPC:

    $ aws ec2 describe-route-tables \
        --filters Name=vpc-id,Values="$RDSVPCID"

The above will show a `RouteTableId`, save it for use later:

    $ export RDSROUTETABLEID="rtb-0fb6edab7ef1496b7"

Next, associate the created subnets with the route table:

    $ aws ec2 associate-route-table \
        --route-table-id "$RDSROUTETABLEID" \
        --subnet-id "$RDSSUBNETID1"
    $ aws ec2 associate-route-table \
        --route-table-id "$RDSROUTETABLEID" \
        --subnet-id "$RDSSUBNETID2"

* Create Subnet Group for RDS

The created subnets need to be added to a single subnet group.

Create the subnet group associated with the created subnets:

    $ aws rds create-db-subnet-group \
        --db-subnet-group-name "test-subnet-group" \
        --db-subnet-group-description "test-subnet-group-description" \
        --subnet-ids "$RDSSUBNETID1" "$RDSSUBNETID2"

* Create VPC Security Group

We need a security group that can be associated with the created VPC, so that we can set network security policies for the joined EKS and RDS networks.

Create the security group:

    $ aws ec2 create-security-group \
        --group-name "test-security-group" \
        --description "test-security-group-description" \
        --vpc-id "$RDSVPCID"

The above will show a `GroupId`, save it for use later:

    $ export SECURITYGROUPID="sg-0f80ba8efa2824209"

* Create RDS Cluster

After creating the subnets and security groups, we can (finally) create an RDS instance using the created security and subnet groups:

    $ aws rds create-db-instance \
        --engine postgres \
        --db-instance-identifier test-postgres-instance \
        --db-instance-class db.t2.micro \
        --allocated-storage 10 \
        --master-username postgres \
        --master-user-password P4ssw0rd \
        --db-name postgres \
        --no-publicly-accessible \
        --vpc-security-group-ids "$SECURITYGROUPID" \
        --availability-zone ap-southeast-1a \
        --db-subnet-group-name test-subnet-group

* Create Elastic Kubernetes Service (EKS) Cluster

Now, we can create our EKS cluster:

    $ eksctl create cluster \
        --name test-cluster \
        --version 1.14 \
        --nodegroup-name standard-workers \
        --node-type t3.medium \
        --nodes 3 \
        --nodes-min 1 \
        --nodes-max 4 \
        --node-ami auto

Alternately, if we already have a working EKS cluster, we can use `eksctl` to setup the credentials for use with `kubectl`:

    $ eksctl utils write-kubeconfig \
        --name test-cluster

*Note:* Creating a new EKS cluster can take 15+ minutes to complete. 

* Test EKS Cluster

First, let's check the status of our EKS nodes, to verify we're able to speak to the EKS cluster with `kubectl`:

    $ kubectl get nodes

Then, let's test a `busybox` image to verify we can launch a pod:

    $ kubectl run test-busybox \
        --rm --tty --stdin \
        --image=busybox \
        --restart=Never -- sh

* Peer EKS and RDS VPCs

We now need to peer the EKS and RDS VPCs, which means creating (and then accepting) a peering connection request from the EKS to RDS VPCs.

First, list active VPCs:

    $ aws ec2 describe-vpcs

The above will show a `VpcId` for each VPC. 

Find the one for the EKS cluster (ie, the one with CIDR of `192.168.0.0/16`), and save for use later:

    $ export EKSVPCID="vpc-0eba65043a65fcc6e"

Then, create a peering connection for EKS to the RDS VPC:

    $ aws ec2 create-vpc-peering-connection \
        --vpc-id "$EKSVPCID" \
        --peer-vpc-id "$RDSVPCID"

* Peer EKS and RDS VPCs (cont'd)

The previous command will show a `VpcPeeringConnectionId`, save it for use later:

    $ export VPCPEERINGID="pcx-0287805248bc7ca9d"

Accept the VPC peering connection:

    $ aws ec2 accept-vpc-peering-connection \
        --vpc-peering-connection-id "$VPCPEERINGID"

* Create Routes for EKS and RDS VPCs

We now will need to create routes between the EKS and RDS VPCs.

First, grab the public route table of the EKS cluster:

    $ aws ec2 describe-route-tables \
        --filters Name="tag:aws:cloudformation:logical-id",Values="PublicRouteTable"

The above will show a `RouteTableId`, save it for use later:

    $ export EKSROUTETABLEID="rtb-010fc5edd9461fc32"

* Create Routes for EKS and RDS VPCs (cont'd)

Now, create routes for EKS to RDS and for RDS to EKS:

    $ aws ec2 create-route \
        --route-table-id "$EKSROUTETABLEID" \
        --vpc-peering-connection-id "$VPCPEERINGID" \
        --destination-cidr-block 10.0.0.0/24

    $ aws ec2 create-route \
        --route-table-id "$RDSROUTETABLEID" \
        --vpc-peering-connection-id "$VPCPEERINGID" \
        --destination-cidr-block 192.168.0.0/16 

Finally, authorize ingress from EKS using the security group we created for RDS:

    $ aws ec2 authorize-security-group-ingress \
        --group-id "$SECURITYGROUPID" \
        --protocol tcp \
        --port 5432 \
        --cidr 192.168.0.0/16

Now pods running on EKS should be able to connect to the RDS instances directly.

* Grab RDS Endpoint for Manifest

First, find the RDS endpoint:

    $ aws rds describe-db-instances

The above should show the RDS instance endpoint `Address`, save it for use later:

    $ export RDSENDPOINT="test-postgres-instance.ce0k8zllu17k.ap-southeast-1.rds.amazonaws.com"

Then, modify `manifests/sample-api.yml`, and change `-db=` value to point to `$RDSENDPOINT`.

* Test EKS to RDS Connectivity and Apply Database Schema

First, run a `postgres` image to test with:

    $ kubectl run test-postgres \
        --rm --tty --stdin \
        --image=postgres \
        --restart=Never -- psql "postgres://postgres:P4ssw0rd@${RDSENDPOINT}/postgres"

Then, from within the launched pod, test connectivity to RDS with `\dt` metacommand:

    If you don't see a command prompt, try pressing enter.
    postgres=> \dt
    Did not find any relations.

Then, copy and paste schema into `postgres=>` prompt.

- Surely better ways to apply schema to RDS, but there was not enough time to research the best way to do that for AWS

* Check Tables Exist

Last, check tables exist, and then quit using `\q`:

    postgres=> \dt
              List of relations
     Schema |  Name   | Type  |  Owner   
    --------+---------+-------+----------
     public | authors | table | postgres
     public | books   | table | postgres
    (2 rows)

    postgres=> \q
    pod "test-postgres" deleted

* Login to Elastic Container Registry (ECR) with Docker 

We need to login to the ECR so that we can push private images that can be used
by EKS.

macOS + Linux:

    $ eval $(aws ecr get-login --no-include-email)
    WARNING! Using --password via the CLI is insecure. Use --password-stdin.
    WARNING! Your password will be stored unencrypted in /home/ken/.docker/config.json.
    Configure a credential helper to remove this warning. See
    https://docs.docker.com/engine/reference/commandline/login/#credentials-store

    Login Succeeded

Windows PowerShell:

    Invoke-Expression -Command (aws ecr get-login --no-include-email)

* Build Docker Image and Create ECR Repository

Build the Docker image:

    $ docker build -t sample-api .

We now need to create a ECR repository where we can push our `sample-api` images:

    $ aws ecr create-repository \
        --repository-name mycompany/sample-api

The above will show a `repositoryUri`, save it for use later:

    $ export REPOSITORYURI=143383525987.dkr.ecr.ap-southeast-1.amazonaws.com/mycompany/sample-api

* Tag and Push Images to ECR

Now we can tag the local Docker images with the private registry name:

    $ docker tag sample-api:latest $REPOSITORYURI:latest

Check the image is tagged correctly:

    $ docker images |grep sample-api

Push the image:

    $ docker push $REPOSITORYURI:latest

Check the image is available in the registry:

    $ aws ecr describe-images \
        --repository-name mycompany/sample-api

* Sample App Manifest

.code manifests/sample-api.yml /api/,/---/

* Sample App Manifest (cont'd)

.code manifests/sample-api.yml /---/,/app:/

Apply manifest:

    $ kubectl apply -f manifests/sample-api.yml

* Test the App

Get exposed service:

    $ kubectl get svc

The above will output the `EXTERNAL-IP` of the Elastic Load Balancer (ELB) created by the manifest. Save it for use later:

    $ export SAMPLEHOST=a20d395f6f4b311e9b0c8021872af61f-898129700.ap-southeast-1.elb.amazonaws.com

Create an author:

    $ curl -d '{ "name": "author1" }' http://$SAMPLEHOST:8080/author

Get an author:

    $ curl http://$SAMPLEHOST:8080/author/1

* Test the App (cont'd)

Delete an author:

    $ curl -X DELETE http://$SAMPLEHOST:8080/author/1

* Scaling to Infinity

* Scale Up Cluster and Pods 

We only created a minimal cluster, so lets make it bigger by adding more nodes:

    $ eksctl scale nodegroup \
        --cluster test-cluster \
        --name standard-workers \
        --nodes 5

Check that the nodes are added to the cluster, and associated with the load balancer:

    $ kubectl get nodes -o wide
    $ kubectl describe svc sample-api-lb

Increase `replicas` in the manifest, and apply:

    $ kubectl apply -f manifests/sample-api-replicas.yml

Alternately:

    $ kubectl scale --replicas=4 deployment/sample-api-deployment

* Update Manifests

Update manifest to increase replicas:

.code manifests/sample-api-replicas.yml

* Update and Rollout New Version

Let's update our app and demonstrate how to rollout a new version. 

We'll add a simple `/books` endpoint to our `sample-api` web app that retrieves a list of all books in the database.

* Build, Tag and Push to Registry

After we've completed our changes, we build new image with Docker:

    $ docker build -t sample-api .

Then, tag a new version:

    $ docker tag sample-api:latest $REPOSITORYURI:v2

And finally, push to the container registry:

    $ docker push $REPOSITORYURI:v2

* Rollout New Deployment Image

After we've pushed the new version of the app, we can roll out the updated version set in the deployment with `kubectl`:

    $ kubectl set image deployment \
        sample-api-deployment \
        sample-api=$REPOSITORYURI:v2

Check on the deployment:

    $ kubectl describe deployment sample-api-deployment

Verify new API works:

    $ curl http://$SAMPLEHOST:8080/books

* Brankas is Hiring!

Brankas is hiring for all positions:

- Country Manager (Indonesia)
- Sales and Marketing
- Solution Architects
- Engineering Managers
- Backend/Frontend Engineers
- Platform and Site Reliability Engineers
- Business Analysts
- QA

Please email a CV / cover letter to: [[mailto:careers@brank.as][careers@brank.as]]

.background brankas-hiring.png

* Misc Commands

Setup credentials for an EKS cluster:

    $ eksctl utils write-kubeconfig \
        --name test-cluster

* Q&A
